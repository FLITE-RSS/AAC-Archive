rsDriver()
rsDriver()
library(RSelenium)
rsDriver() -> rSel
rsDriver() -> rSel
rsDriver(verbose=TRUE, port=4837L, browserName='chrome', check=TRUE) -> rSel
rsDriver(verbose=TRUE, port=4837L, browserName="chrome", check=TRUE) -> rSel
rsDriver(verbose=TRUE, port=4837L, browserName="chrome", check=TRUE) -> rSel
library(RSelenium)
rsDriver(verbose=TRUE, port=4837L, browserName="chrome", check=TRUE) -> rSel
4837L
remDr <- remoteDriver(verbose=TRUE,
remoteServerAddr = "localhost",
port = 4445L,
browserName = "firefox"
)
remDr <- rsDriver(verbose=TRUE,
remoteServerAddr = "localhost",
port = 4445L,
browserName = "firefox"
)
remDr <- remoteDriver(
remoteServerAddr = "localhost",
port = 4445L,
browserName = "firefox"
)
remDr$open
remDr$open9
remDr$open()
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
restart()
library(RSelenium)
remDr <- remoteDriver(
remoteServerAddr = "localhost",
port = 4445L,
browserName = "chrome"
)
remDr$open()
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
rD <- rsDriver()
remDr <- rD[["client"]]
library(RSelenium)
rD <- rsDriver()
remDr <- rD[["client"]]
?rsDriver
rD <- rsDriver(version="101")
remDr <- rD[["client"]]
rD <- rsDriver(browser="chrome")
remDr <- rD[["client"]]
remDr <- rD[["client"]]
library(RSelenium)
rD <- rsDriver(browser="chrome", chromever="101")
rD <- rsDriver(browser="chrome", chromever="101.0.4951.41")
remDr <- rD[["client"]]
url <- "https://ferris.libguides.com/"
browser$navigate(url)
browser <- remDr$client
browser$open()
remDr$open()
remDr$navigate(url)
pagesource <- remDr$getPageSource()
pagesource
html <- read_html(pagesource[[1]])
library(rvest)
html <- read_html(pagesource[[1]])
html
html %>% html_nodes(".s-lg-gtitle")
html %>% html_nodes(".s-lg-gtitle a")
html %>% html_nodes(".panel-header")
html %>% html_nodes(".panel-heading")
html %>% html_nodes(".panel-heading div")
html %>% html_nodes(".panel-heading div.bold")
html %>% html_nodes(".panel-heading div.bold") %>% html_text()
headers <- html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
strsplit(headers[[1]], ",")
split_headers <- function(myStr) {
trimws(strsplit(myStr, ",")) -> strList
return(strList)
}
sapply(headers, split_headers)
lapply(headers, split_headers)
split_headers <- function(myStr) {
trimws(strsplit(myStr, ",")) -> strList
return(unlist(strList))
}
lapply(headers, split_headers)
headers[[1]] -> myStr
trimws(strsplit(myStr, ",")) -> strList
strList
strsplit(myStr, ",") -> strList
strList
lapply(strList, trimws)
split_headers <- function(myStr) {
strsplit(myStr, ",") -> strList
lapply(strList, trimws) -> strList
return(strList)
}
lapply(headers, split_headers)
split_headers <- function(myStr) {
strsplit(myStr, ",") -> strList
sapply(strList, trimws) -> strList
return(strList)
}
lapply(headers, split_headers)
sapply(headers, split_headers)
strsplit(myStr, ",") -> strList
lapply(strList, trimws) -> strList
strList
unlist(strList)
split_headers <- function(myStr) {
strsplit(myStr, ",") -> strList
lapply(strList, trimws) -> strList
return(unlist(strList))
}
sapply(headers, split_headers)
lapply(headers, split_headers)
sapply(headers, split_headers)
lapply(headers, split_headers)
lapply(headers, split_headers) -> test
test[[1]]
test[[1]][1]
mk_header_dir <- function(myHeader) {
myDir <- myHeader[1]
if(!dir.exists(myDir)) {
dir.create(myDir)
}
}
mk_header_dir <- function(myHeader) {
myDir <- paste(dataDir, myHeader[1], sep="/")
if(!dir.exists(myDir)) {
dir.create(myDir)
}
}
lapply(headers, split_headers) -> headerList
lapply(headerList, mk_header_dir)-> headerDirList
headerDirList
headerList
headerList
html %>% html_nodes(.panel)
html %>% html_nodes(".panel")
html %>% html_nodes(".panel") -> panels
headerList
panels[[1]]
read_guides <- function(n, headerList, panels) {
myDir <- paste(dataDir, headerList[[n]][1], sep="/")
myLinks <- panels[[n]] %>%
html_nodes(".s-lg-gtitle a") %>%
html_attr("href")
myTitles <- panels[[n]] %>%
html_nodes(".s-lg-gtitle a") %>%
html_text()
pagesDF <- data.table("link"=myLinks, "committee"=myTitles)
return(pagesDF)
}
lapply(c(1:length(headerList)), read_guides, headerList, panels) -> pageTables
library(data.table)
lapply(c(1:length(headerList)), read_guides, headerList, panels) -> pageTables
pageTables
scape_libguides <- function(myN, pageTables, headerList) {
dataDir <-  paste(dataDir, headerList[myN], sep="/")
message(dataDir)
}
lapply(c(1:nrow(pageTables)), scrape_libguides, pageTables)
scrape_libguides <- function(myN, pageTables, headerList) {
dataDir <-  paste(dataDir, headerList[myN], sep="/")
message(dataDir)
}
lapply(c(1:nrow(pageTables)), scrape_libguides, pageTables)
pageTables
lapply(c(1:length(pageTables)), scrape_libguides, pageTables)
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList)
scrape_libguides <- function(myN, pageTables, headerList) {
dataDir <-  paste(dataDir, headerList[[myN]][1], sep="/")
message(dataDir)
}
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList)
dataDir <- "/Users/peterbradley/Documents/GitHub/AAC-Archive/SpringshareBackup/"
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList)
pageTables[[1]]
scrape_libguides <- function(myN, pageTables, headerList) {
dataDir <-  paste(dataDir, headerList[[myN]][1], sep="/")
message("Doing ", dataDir)
scrape_committee(myN, pageTables[[myN]])
}
scrape_libguides(1, pageTables, headerList)
library(rvest)
library(RSelenium)
library(data.table)
library(tidyverse)
library(webshot)
scrape_libguides(1, pageTables, headerList)
myN <- 1
lapply(c(1:nrow(pageTables[[myN]])), scrape_committee, pageTables[[myN]])
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
headerList
headers
html
html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
pagesource <- remDr$getPageSource()
pagesource
html <- read_html(pagesource[[1]])
html
html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
headers <- html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
lapply(headers, split_headers) -> headerList
lapply(headerList, mk_header_dir)-> headerDirList
html %>% html_nodes(".panel") -> panels
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
myN
headerList[[myN]][1]
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
html %>% html_nodes(".panel") -> panels
## Header list an panels are in the same order
read_guides <- function(n, headerList, panels) {
myDir <- paste(dataDir, headerList[[n]][1], sep="/")
myLinks <- panels[[n]] %>%
html_nodes(".s-lg-gtitle a") %>%
html_attr("href")
myTitles <- panels[[n]] %>%
html_nodes(".s-lg-gtitle a") %>%
html_text()
pagesDF <- data.table("link"=myLinks, "title"=myTitles)
return(pagesDF)
}
lapply(c(1:length(headerList)), read_guides, headerList, panels) -> pageTables
scrape_libguides <- function(myN, pageTables, headerList) {
dataDir <<-  paste(dataDir, headerList[[myN]][1], sep="/")
message("Doing ", dataDir)
lapply(c(1:nrow(pageTables[[myN]])), scrape_committee, pageTables[[myN]])
}
### Do the AAC
url <- "https://ferris.libguides.com/aacinfohub/home"
page <- read_html(url)
aacdir <- paste(dataDir, "/AACInfoHub/", sep="")
if(!dir.exists(aacdir)) {
dir.create(aacdir)
}
aacnav <- page %>%
html_nodes(".nav li")
committees <- aacnav %>%
html_nodes("a") %>%
html_text()
committeelinks <- aacnav %>%
html_nodes("a") %>%
html_attr("href")
committeeDF <- data.table("link"=committeelinks, "title"=committees)
download_annual_report <- function(myN, myDF, dataDir) {
link <- myDF[myN,]$link
title <- paste(gsub("[[:space:]]", "", myDF[myN,]$title), "docx", sep=".")
myDir <- paste(dataDir, myDF[myN,]$safe_committee, sep="/")
download.file(link, destfile = paste(myDir, title, sep="/"))
}
scrape_committee <- function(myN, myDF, dataDir) {
title <- myDF[myN,]$title
link <- myDF[myN,]$link
message("Doing ", link)
safe_title <- gsub("&", "and", title)
safe_title <- gsub("[[:space:]]", "_", safe_title)
myDir <- paste(dataDir, safe_title, sep="/")
if(!dir.exists(myDir)) {
dir.create(myDir)
}
page <- read_html(link)
download.file(link, destfile=paste(myDir, "/", safe_title, ".html", sep=""))
webshot(link, file=paste(myDir, "/", safe_title, ".png", sep=""))
links <-  page %>%
html_nodes("a") %>%
html_attr("href")
titles <- page %>%
html_nodes("a") %>%
html_text()
page_set <- data.table("title"=titles, "link"=links, "safe_title"=safe_title)
todo <- page_set %>%
filter(grepl("^http.*", link)) %>%
filter(grepl("content_id", link))
if(nrow(todo) > 0) {
lapply(c(1:nrow(todo)), download_annual_report, todo)
}
}
lapply(c(5:nrow(committeeDF)), scrape_committee, committeeDF, aacdir)
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, dataDir)
scrape_libguides <- function(myN, pageTables, headerList) {
dataDir <<-  paste(dataDir, headerList[[myN]][1], sep="/")
message("Doing ", dataDir)
lapply(c(1:nrow(pageTables[[myN]])), scrape_committee, pageTables[[myN]], dataDir)
}
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, dataDir)
scrape_libguides <- function(myN, pageTables, headerList) {
dataDir <<-  paste(dataDir, headerList[[myN]][1], sep="/")
message("Doing ", dataDir)
# lapply(c(1:nrow(pageTables[[myN]])), scrape_committee, pageTables[[myN]], dataDir)
}
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, dataDir)
headerList
Tables)
length(pageTables)
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
headerList[[1]]
headerList[[1]][1]
scrape_libguides <- function(myN, pageTables, headerList, dataDir) {
dataDir <<-  paste(dataDir, headerList[[myN]][1], sep="/")
message("Doing ", dataDir)
# lapply(c(1:nrow(pageTables[[myN]])), scrape_committee, pageTables[[myN]], dataDir)
}
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
scrape_libguides <- function(myN, pageTables, headerList, dataDir) {
dataDir <-  paste(dataDir, headerList[[myN]][1], sep="/")
#  message("Doing ", dataDir)
lapply(c(1:nrow(pageTables[[myN]])), scrape_committee, pageTables[[myN]], dataDir)
}
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
scrape_libguides <- function(myN, pageTables, headerList, dataDir) {
dataDir <-  paste(dataDir, headerList[[myN]][1], sep="/")
message("Doing ", dataDir)
lapply(c(1:nrow(pageTables[[myN]])), scrape_committee, pageTables[[myN]], dataDir)
}
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
dataDir <- "/Users/peterbradley/Documents/GitHub/AAC-Archive/SpringshareBackup/"
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
lapply(c(1:length(pageTables)), scrape_libguides, pageTables, headerList, dataDir)
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
library(rvest)
library(RSelenium)
library(data.table)
library(tidyverse)
library(webshot)
# docker run -d -p 4444:4444 --shm-size="2g" selenium/standalone-chrome:4.1.4-20220427
## To stop:
# docker stop $(docker ps -q)
## Basic settings - set the site of your document repository
## And the first page to start your crawl
dataDir <- "/Users/peterbradley/Documents/GitHub/AAC-Archive/SpringshareBackup/"
url <- "https://ferris.libguides.com/"
page <- read_html(url)
library(RSelenium)
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
headerList
html
headers <- html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
headers
html %>%
html_nodes(".panel-heading div.bold")
html %>%
html_nodes(".panel-heading")
pagesource
html <- read_html(pagesource[[1]])
html
html %>% html_nodes(".panel")
pagesource[[1]]
remDr$getPageSource()
?getpageSource
??getPageSource
?rsDriver
rD[["server"]]$stop()
rD[["server"]]$start()
rD <- rsDriver(browser="chrome", chromever="101.0.4951.41")
remDr <- rD[["client"]]
remDr$navigate(url)
pagesource <- remDr$getPageSource()
html <- read_html(pagesource[[1]])
html
html %>% html_nodes(".panel")
headers <- html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
headers
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
rD[["server"]]$stop()
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
headers <- html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
headers
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
remDr$navigate(url)
pagesource <- remDr$getPageSource()
html <- read_html(pagesource[[1]])
split_headers <- function(myStr) {
strsplit(myStr, ",") -> strList
lapply(strList, trimws) -> strList
return(unlist(strList))
}
mk_header_dir <- function(myHeader) {
myDir <- paste(dataDir, myHeader[1], sep="/")
if(!dir.exists(myDir)) {
dir.create(myDir)
}
}
headers <- html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
headers
remDr$navigate(url)
pagesource <- remDr$getPageSource()
html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
rD[["server"]]$stop()
dataDir <- "/Users/peterbradley/Documents/GitHub/AAC-Archive/SpringshareBackup/"
url <- "https://ferris.libguides.com/"
page <- read_html(url)
library(RSelenium)
rD <- rsDriver(browser="chrome", chromever="101.0.4951.41")
remDr <- rD[["client"]]
remDr$open()
remDr$navigate(url)
pagesource <- remDr$getPageSource()
pagesource
html <- read_html(pagesource[[1]])
html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
?wait
??wait
tryCatch({remDr$findElement(using = 'class', value = "panel-heading")},
error = function(e){NULL})
tryCatch({remDr$findElement(using = 'class', value = "panel-heading")},
error = function(e){NULL})
remDr$open()
remDr$navigate(url)
remDr$open()
remDr$navigate(url)
remDr$findElement(using = 'class', value = "panel-heading")
remDr$findElement(using = 'class', value = "panel-heading")
remDr$findElement(using = 'class', value = "panel-heading")
remDr$findElement(using = 'class', value = "panel-heading")
remDr$findElement(using = 'css selector', value = ".panel-heading")
remDr$findElement(using = 'css selector', value = ".panel-heading")
webElem <-NULL
while(is.null(webElem)){
webElem <- tryCatch({remDr$findElement(using = 'css selector', value = ".panel-heading")},
error = function(e){NULL})
#loop until element with name <value> is found in <webpage url>
}
webElem
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
webElem <-NULL
while(is.null(webElem)){
webElem <- tryCatch({remDr$findElement(using = 'css selector', value = ".panel-heading")},
error = function(e){NULL})
#loop until element with name <value> is found in <webpage url>
}
rD[["server"]]$stop()
source("~/Documents/GitHub/AAC-Archive/crawlAAC.R")
rD[["server"]]$stop()
library(rvest)
library(RSelenium)
library(data.table)
library(tidyverse)
library(webshot)
# docker run -d -p 4444:4444 --shm-size="2g" selenium/standalone-chrome:4.1.4-20220427
## To stop:
# docker stop $(docker ps -q)
## Basic settings - set the site of your document repository
## And the first page to start your crawl
dataDir <- "/Users/peterbradley/Documents/GitHub/AAC-Archive/SpringshareBackup/"
url <- "https://ferris.libguides.com/"
page <- read_html(url)
library(RSelenium)
rD <- rsDriver(browser="chrome", chromever="101.0.4951.41")
remDr <- rD[["client"]]
remDr$open()
remDr$navigate(url)
webElem <-NULL
while(is.null(webElem)){
webElem <- tryCatch({remDr$findElement(using = 'css selector', value = ".panel-heading")},
error = function(e){NULL})
#loop until element with name <value> is found in <webpage url>
}
pagesource <- remDr$getPageSource()
html <- read_html(pagesource[[1]])
html
html %>%
html_nodes(".panel-heading div.bold") %>%
html_text()
